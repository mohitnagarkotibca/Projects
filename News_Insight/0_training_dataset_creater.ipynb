{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_md\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz (120.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\http\\client.py\", line 461, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\http\\client.py\", line 505, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\ssl.py\", line 1071, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\ssl.py\", line 929, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 205, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 319, in run\n",
      "    reqs, check_supported_wheels=not options.target_dir\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 104, in resolve\n",
      "    req, requested_extras=()\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 434, in make_requirement_from_install_req\n",
      "    version=None,\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 205, in _make_candidate_from_link\n",
      "    version=version,\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 312, in __init__\n",
      "    version=version,\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 151, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 234, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 318, in _prepare_distribution\n",
      "    self._ireq, parallel_builds=True\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 552, in _prepare_linked_requirement\n",
      "    self.download_dir, hashes\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 243, in unpack_url\n",
      "    hashes=hashes,\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 157, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 152, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 86, in response_chunks\n",
      "    decode_content=False,\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\projects\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='github-releases.githubusercontent.com', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the training dataset\n",
    "\n",
    "The dataset used in this project is the BBC News Raw Dataset. It can be downloaded from:\n",
    "\n",
    "http://mlg.ucd.ie/datasets/bbc.html\n",
    "\n",
    "It consists of 2225 documents from the BBC news website corresponding to stories in five topical areas from 2004 to 2005. These areas are:\n",
    "\n",
    "    Business\n",
    "    Entertainment\n",
    "    Politics\n",
    "    Sport\n",
    "    Tech\n",
    "\n",
    "In the same webpage we can find another dataset (BBCSport), which consists of 737 documents from the BBC Sport website. However, in this project it hasn't been used.\n",
    "\n",
    "So, Basically since this is a Supervised Machine Learning project i have used BBC files to make a training dataset, Which will be used to predict all the news which my Scrapper will scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(columns=['file_name','category','content'])\n",
    "categories= os.listdir('files/')\n",
    "for cat in categories:\n",
    "    all_files= os.listdir(f'files/{cat}/')\n",
    "    files= list( filter(lambda x: x[-4:]=='.txt',all_files))\n",
    "    for file in files:\n",
    "        with open(f'files/{cat}/{file}') as f:\n",
    "            df= df.append({'file_name':file,'category':cat,'content':f.read()},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>397.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>398.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>399.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>400.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>401.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name  category                                            content\n",
       "0      001.txt  business  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1      002.txt  business  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2      003.txt  business  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3      004.txt  business  High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4      005.txt  business  Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "...        ...       ...                                                ...\n",
       "2220   397.txt      tech  BT program to beat dialler scams\\n\\nBT is intr...\n",
       "2221   398.txt      tech  Spam e-mails tempt net shoppers\\n\\nComputer us...\n",
       "2222   399.txt      tech  Be careful how you code\\n\\nA new European dire...\n",
       "2223   400.txt      tech  US cyber security chief resigns\\n\\nThe man mak...\n",
       "2224   401.txt      tech  Losing yourself in online gaming\\n\\nOnline rol...\n",
       "\n",
       "[2225 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/news_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('data/news_dataset_v1.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>397.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>398.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>399.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>400.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>401.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name  category                                            content\n",
       "0      001.txt  business  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1      002.txt  business  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2      003.txt  business  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3      004.txt  business  High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4      005.txt  business  Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "...        ...       ...                                                ...\n",
       "2220   397.txt      tech  BT program to beat dialler scams\\n\\nBT is intr...\n",
       "2221   398.txt      tech  Spam e-mails tempt net shoppers\\n\\nComputer us...\n",
       "2222   399.txt      tech  Be careful how you code\\n\\nA new European dire...\n",
       "2223   400.txt      tech  US cyber security chief resigns\\n\\nThe man mak...\n",
       "2224   401.txt      tech  Losing yourself in online gaming\\n\\nOnline rol...\n",
       "\n",
       "[2225 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sport            511\n",
    "# business         510\n",
    "# politics         417\n",
    "# tech             401\n",
    "# entertainment    386\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business category :\u001b[1m 510 \u001b[0m articles available\n",
      "entertainment category :\u001b[1m 386 \u001b[0m articles available\n",
      "politics category :\u001b[1m 417 \u001b[0m articles available\n",
      "sport category :\u001b[1m 511 \u001b[0m articles available\n",
      "tech category :\u001b[1m 401 \u001b[0m articles available\n"
     ]
    }
   ],
   "source": [
    "for group in data.groupby('category').groups.keys():\n",
    "    print(group,'category :\\033[1m',len(data.groupby('category').get_group(group)),'\\033[0m articles available')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
